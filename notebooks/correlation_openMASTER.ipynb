{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenMASTER - correlations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyomo.environ as pyo\n",
    "import openMASTER\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the abstract model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyomo.core.base.PyomoModel.AbstractModel at 0x204e7de4770>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = openMASTER.make_model()\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model data upload\n",
    "\n",
    "* If you haven't created the .csv files, please:\n",
    "    * Be aware the openMASTER_Data.xlsx file has to be downloaded using git-lfs or the following link:\n",
    "        https://github.com/IIT-EnergySystemModels/openMASTER/raw/main/data/input/openMASTER_Data.xlsx?download=\n",
    "    * Run the first line of code in this cell, which will both create the .csv files and load them into the DataPortal (this whole function takes several minutes)\n",
    "\n",
    "* On the contrary, if you have already created the .csv files from the Excel file and haven't changed them, you can directly go on to the second line of code. This will save some minutes.\n",
    "\n",
    "In any case, add \"#\" in front of the line you are not running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = openMASTER.load_dataportal_from_excel('../data/input/openMASTER_Data.xlsx')\n",
    "#data = openMASTER.load_dataportal_from_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal components analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.04795226e+00 -5.65824031e+00 -4.68260004e+00 -1.04196591e+01\n",
      "   9.85916667e+00 -5.13000000e+00 -5.13000000e+00 -5.13000000e+00\n",
      "  -5.13000000e+00 -2.72900000e+03  1.14300000e+03  2.87601012e+03\n",
      "   1.64231053e+03  2.79132632e+03  3.38000000e+02  1.11333902e+03\n",
      "   1.49537815e+02  4.92562974e+02 -2.24421953e+02 -1.06514200e+03\n",
      "  -2.65224328e+03 -2.24421953e+02  3.66000000e+02  1.12100000e+03\n",
      "   1.22687300e+03  6.86000000e+02  6.86000000e+02 -5.97092000e+02\n",
      "   1.38700000e+03  2.43515635e+03  3.13000000e+02  4.74716666e+02\n",
      "   4.84809782e+02  7.12075000e+02]\n",
      " [ 4.92572327e-01 -7.01216418e+00 -1.68682462e+01 -1.91241814e+01\n",
      "  -1.67075000e+01 -7.13000000e+00 -7.13000000e+00 -7.13000000e+00\n",
      "  -7.13000000e+00 -3.92900000e+03 -6.70000000e+01 -1.68585020e+02\n",
      "  -9.62684215e+01 -1.63621053e+02 -7.20000000e+01 -2.37160976e+02\n",
      "  -1.12310924e+02 -3.69941228e+02 -4.41171953e+02 -9.16322000e+02\n",
      "  -2.30075393e+03 -4.41171953e+02  2.60000000e+01  6.71000000e+02\n",
      "   5.91503000e+02  4.56000000e+02  4.56000000e+02  1.60095800e+03\n",
      "   4.77000000e+02  8.37469055e+02  1.30000000e+01  1.97166665e+01\n",
      "   2.01358695e+01  2.95750000e+01]\n",
      " [-2.47341923e-01 -4.55819813e+00 -1.74534630e+01 -1.95422169e+01\n",
      "  -1.52991667e+01 -1.10300000e+01 -1.10300000e+01 -1.10300000e+01\n",
      "  -1.10300000e+01 -3.39900000e+03  5.30000000e+01  1.33358299e+02\n",
      "   7.61526315e+01  1.29431579e+02  8.80000000e+01  2.89863415e+02\n",
      "  -1.01260505e+01 -3.33542218e+01  7.35804680e+00 -6.03112000e+02\n",
      "  -1.56100137e+03  7.35804680e+00  2.60000000e+01 -5.09000000e+02\n",
      "   2.45203000e+02  3.26000000e+02  3.26000000e+02  1.60095800e+03\n",
      "   3.77000000e+02  6.61899022e+02  1.30000000e+01  1.97166665e+01\n",
      "   2.01358695e+01  2.95750000e+01]\n",
      " [-8.32143940e-01 -3.00139486e+00 -1.58648071e+01 -1.84073989e+01\n",
      "  -1.09191667e+01 -1.11300000e+01 -1.11300000e+01 -1.11300000e+01\n",
      "  -1.11300000e+01 -2.16900000e+03 -7.00000000e+00 -1.76133607e+01\n",
      "  -1.00578945e+01 -1.70947367e+01  1.28000000e+02  4.21619512e+02\n",
      "   1.54201680e+01  5.07925292e+01  2.78732805e+03 -5.59632000e+02\n",
      "  -1.45830847e+03  2.78732805e+03 -1.40000000e+01 -2.99000000e+02\n",
      "  -1.44797000e+02 -7.40000000e+01 -7.40000000e+01  1.43810800e+03\n",
      "   2.97000000e+02  5.21442996e+02 -1.70000000e+01 -2.57833335e+01\n",
      "  -2.63315215e+01 -3.86750000e+01]\n",
      " [-1.48823978e+00 -1.98729378e+00 -9.76400242e+00 -1.40494363e+01\n",
      "   2.90916667e+00 -9.83000000e+00 -9.83000000e+00 -9.83000000e+00\n",
      "  -9.83000000e+00  1.13100000e+03 -1.67000000e+02 -4.20204454e+02\n",
      "  -2.39952632e+02 -4.07831579e+02 -1.02000000e+02 -3.35978049e+02\n",
      "  -1.25420168e+02 -4.13121798e+02  6.47680468e+01  4.47368000e+02\n",
      "   9.20066526e+02  6.47680468e+01 -8.40000000e+01 -3.59000000e+02\n",
      "  -2.64797000e+02 -1.74000000e+02 -1.74000000e+02 -8.85282000e+02\n",
      "   3.27000000e+02  5.74114006e+02 -1.70000000e+01 -2.57833335e+01\n",
      "  -2.63315215e+01 -3.86750000e+01]\n",
      " [-9.40048102e-01 -6.35359097e+00 -2.34320221e+01 -1.82518657e+01\n",
      "  -2.92250000e+00 -3.83000000e+00 -3.83000000e+00 -3.83000000e+00\n",
      "  -3.83000000e+00  9.01000000e+02 -2.27000000e+02 -5.71176114e+02\n",
      "  -3.26163158e+02 -5.54357895e+02 -6.20000000e+01 -2.04221951e+02\n",
      "  -2.54201681e+01 -8.37315538e+01 -4.45521953e+02  4.37368000e+02\n",
      "   8.96448105e+02 -4.45521953e+02 -1.14000000e+02 -4.19000000e+02\n",
      "  -3.04797000e+02 -2.24000000e+02 -2.24000000e+02  6.04388000e+02\n",
      "  -1.31300000e+03 -2.30523453e+03 -5.70000000e+01 -8.64499995e+01\n",
      "  -8.82880435e+01 -1.29675000e+02]\n",
      " [-1.71657269e+00 -7.16874064e+00 -2.41521082e+01 -2.12554889e+01\n",
      "  -2.21141667e+01 -4.63000000e+00 -4.63000000e+00 -4.63000000e+00\n",
      "  -4.63000000e+00  2.62100000e+03 -1.17000000e+02 -2.94394737e+02\n",
      "  -1.68110527e+02 -2.85726316e+02 -1.92000000e+02 -6.32429268e+02\n",
      "  -5.42016806e+00 -1.78535048e+01 -6.62019532e+01  6.57368000e+02\n",
      "   1.76644811e+03 -6.62019532e+01 -1.40000000e+01  5.81000000e+02\n",
      "  -4.34797000e+02 -3.44000000e+02 -3.44000000e+02 -1.70049200e+03\n",
      "  -7.33000000e+02 -1.28692834e+03 -1.70000000e+01 -2.57833335e+01\n",
      "  -2.63315215e+01 -3.86750000e+01]\n",
      " [ 6.70927308e-01  5.34900862e+00  3.54388130e+01  3.93533698e+01\n",
      "   6.69916667e+00 -5.33000000e+00 -5.33000000e+00 -5.33000000e+00\n",
      "  -5.33000000e+00  2.79100000e+03 -1.47000000e+02 -3.69880567e+02\n",
      "  -2.11215790e+02 -3.58989474e+02 -1.22000000e+02 -4.01856097e+02\n",
      "   5.45798319e+01  1.79780641e+02 -5.08541953e+02  6.07368000e+02\n",
      "   1.64644811e+03 -5.08541953e+02  6.00000000e+00  4.81000000e+02\n",
      "  -4.04797000e+02 -3.34000000e+02 -3.34000000e+02  2.94871800e+03\n",
      "  -7.33000000e+02 -1.28692834e+03 -4.70000000e+01 -7.12833335e+01\n",
      "  -7.27989135e+01 -1.06925000e+02]\n",
      " [ 1.77448287e+00  2.63978966e+01  7.05984133e+01  7.27319567e+01\n",
      "   3.36791667e+01  2.53700000e+01  2.53700000e+01  2.53700000e+01\n",
      "   2.53700000e+01  2.65100000e+03 -1.77000000e+02 -4.45366397e+02\n",
      "  -2.54321053e+02 -4.32252632e+02  1.80000000e+01  5.92902440e+01\n",
      "   4.45798319e+01  1.46841617e+02 -5.36998402e+02  5.67368000e+02\n",
      "   1.54644811e+03 -5.36998402e+02 -8.40000000e+01 -2.19000000e+02\n",
      "  -2.74797000e+02 -1.74000000e+02 -1.74000000e+02 -2.50513200e+03\n",
      "   8.70000000e+01  1.52745928e+02 -5.70000000e+01 -8.64499995e+01\n",
      "  -8.82880435e+01 -1.29675000e+02]\n",
      " [ 3.33431620e+00  3.99271761e+00  6.18002267e+00  8.96492065e+00\n",
      "   1.48158333e+01  3.26700000e+01  3.26700000e+01  3.26700000e+01\n",
      "   3.26700000e+01  2.13100000e+03 -2.87000000e+02 -7.22147773e+02\n",
      "  -4.12373685e+02 -7.00884211e+02 -2.20000000e+01 -7.24658540e+01\n",
      "   1.45798319e+01  4.80245442e+01 -6.36595972e+02  4.27368000e+02\n",
      "   1.19644811e+03 -6.36595972e+02 -1.14000000e+02 -1.04900000e+03\n",
      "  -2.34797000e+02 -1.44000000e+02 -1.44000000e+02 -2.50513200e+03\n",
      "  -1.73000000e+02 -3.03736157e+02 -1.27000000e+02 -1.92616667e+02\n",
      "  -1.96711957e+02 -2.88925000e+02]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afrmatas\\AppData\\Local\\Temp\\ipykernel_11816\\404563478.py:11: RuntimeWarning: invalid value encountered in divide\n",
      "  X_z        = X_o / np.std (X_o, axis=0)\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m pca1 \u001b[38;5;241m=\u001b[39m PCA()\n\u001b[0;32m     51\u001b[0m pca1\u001b[38;5;241m.\u001b[39mfit(X_o)\n\u001b[1;32m---> 53\u001b[0m u2, s2, vh2 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_z\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m pca2 \u001b[38;5;241m=\u001b[39m PCA()\n\u001b[0;32m     55\u001b[0m pca2\u001b[38;5;241m.\u001b[39mfit(X_z)\n",
      "File \u001b[1;32mc:\\Users\\afrmatas\\Documents\\openMASTER_GitHub\\.venv\\lib\\site-packages\\numpy\\linalg\\linalg.py:1681\u001b[0m, in \u001b[0;36msvd\u001b[1;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[0;32m   1678\u001b[0m         gufunc \u001b[38;5;241m=\u001b[39m _umath_linalg\u001b[38;5;241m.\u001b[39msvd_n_s\n\u001b[0;32m   1680\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->DdD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->ddd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1681\u001b[0m u, s, vh \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1682\u001b[0m u \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1683\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mastype(_realType(result_t), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\afrmatas\\Documents\\openMASTER_GitHub\\.venv\\lib\\site-packages\\numpy\\linalg\\linalg.py:121\u001b[0m, in \u001b[0;36m_raise_linalgerror_svd_nonconvergence\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_svd_nonconvergence\u001b[39m(err, flag):\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: SVD did not converge"
     ]
    }
   ],
   "source": [
    "csv_mean   = '..\\data\\input\\mean.csv'\n",
    "df_mean    = pd.read_csv(csv_mean, delimiter=';', header=[0])\n",
    "X_mean     = df_mean.values\n",
    "\n",
    "\n",
    "csv_data   = '..\\data\\input\\costs_correl.csv'\n",
    "df_data    = pd.read_csv(csv_data, delimiter=';', header=[0])\n",
    "X_data     = df_data.values\n",
    "X_o        = X_data - np.mean(X_data, axis=0)\n",
    "\n",
    "X_z        = X_o / np.std (X_o, axis=0)\n",
    "#X_z        = np.nan_to_num(X_z, nan=0.0)\n",
    "\n",
    "# Encontrar las columnas con valores NaN en X_z\n",
    "columns_with_nan = np.isnan(X_z).any(axis=0)\n",
    "\n",
    "# Eliminar las columnas con valores NaN en X_z\n",
    "X_z_clean = X_z[:, ~columns_with_nan]\n",
    "\n",
    "# Eliminar las mismas columnas en X_o\n",
    "X_o_clean = X_o[:, ~columns_with_nan]\n",
    "\n",
    "print(X_o_clean)\n",
    "\n",
    "#csv_covar  = '..\\data\\input\\covar.xlsx'\n",
    "#sheet_name = 'covar'\n",
    "#df_covar   = pd.read_excel(csv_covar, sheet_name=sheet_name, index_col=0)\n",
    "#X_covar    = df_covar.values\n",
    "\n",
    "\n",
    "f_set   = data['f']\n",
    "unc_set = data['sUnc']\n",
    "\n",
    "\n",
    "# Compute the mean for each column\n",
    "\n",
    "#s_bar_dict = {unc: s_bar[i-1] for i, unc in enumerate(unc_set)}\n",
    "\n",
    "#usamos cov de la serie de datos histórica, pero centrados en la media de los valores nominales para el año 2030\n",
    "#new_data = np.random.multivariate_normal(np.ravel(X_mean), X_covar, size=10000)\n",
    "#new_data_o = new_data - np.ravel(X_mean)\n",
    "\n",
    "s_bar_dict = {unc: np.ravel(X_mean)[i] for i, unc in enumerate(unc_set)}\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "#we compute the singular value decomposition\n",
    "\n",
    "u1, s1, vh1 = np.linalg.svd(np.cov(X_o.T), full_matrices=True)\n",
    "pca1 = PCA()\n",
    "pca1.fit(X_o)\n",
    "\n",
    "u, s, vh = np.linalg.svd(np.cov(X_z.T), full_matrices=True)\n",
    "pca2 = PCA()\n",
    "pca2.fit(X_z)\n",
    "\n",
    "# Comparar los componentes principales obtenidos de ambos métodos\n",
    "print(\"Componentes principales obtenidos por el método 1:\")\n",
    "print(pca1.components_)\n",
    "print(\"\\nComponentes principales obtenidos por el método 2:\")\n",
    "print(pca2.components_)\n",
    "\n",
    "# Comprobación de similitud\n",
    "similarity = np.allclose(pca1.components_, pca2.components_)\n",
    "print(\"\\n¿Los componentes principales son similares?\", similarity)\n",
    "\n",
    "\n",
    "##np.linalg.svd --> Singular Value Decomposition:\n",
    "##np.cov --> estimate the covariance matrix\n",
    "##u is eigenvector matrix and s are the eigenvalues\n",
    "\n",
    "#now we compute the vectors needed to build the uncertainty region\n",
    "w_max = np.max(np.dot(X_o, u) / np.linalg.norm(u, axis=0), 0)\n",
    "w_max_dict = {f_i: w_max[i-1] for i, f_i in enumerate(f_set)}\n",
    "\n",
    "w_min = np.min(np.dot(X_o, u) / np.linalg.norm(u, axis=0), 0)\n",
    "w_min_dict = {f_i: w_min[i-1] for i, f_i in enumerate(f_set)}\n",
    "\n",
    "alpha_up = (w_max / np.linalg.norm(u, axis=0)) * u\n",
    "alpha_up_dict = {(f_i, unc): alpha_up[i, j] for i, f_i in enumerate(f_set) for j, unc in enumerate(unc_set)}\n",
    "\n",
    "alpha_do = (w_min / np.linalg.norm(u, axis=0)) * u\n",
    "alpha_do_dict = {(f_i, unc): alpha_do[i, j] for i, f_i in enumerate(f_set) for j, unc in enumerate(unc_set)}\n",
    "\n",
    "rest = ((w_max + w_min) / (2 * np.linalg.norm(u, axis=0))) * u\n",
    "rest_dict = {(f_i, unc): rest[i, j] for i, f_i in enumerate(f_set) for j, unc in enumerate(unc_set)}\n",
    "\n",
    "\n",
    "data._data[None][m.pS.name]        = s_bar_dict\n",
    "data._data[None][m.pW_max.name]    = w_max_dict\n",
    "data._data[None][m.pW_min.name]    = w_min_dict\n",
    "data._data[None][m.pAlpha_up.name] = alpha_up_dict\n",
    "data._data[None][m.pAlpha_do.name] = alpha_do_dict\n",
    "data._data[None][m.pRest.name]     = rest_dict\n",
    "\n",
    "#print(s_bar_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the instance of the abstract model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = m.create_instance(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data._data[None][m.pCECapex.name]\n",
    "#instance.pS.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the model instance\n",
    "\n",
    "To solve the model instance, please select a solver within the Pyomo SolverFactory. Please note that any solver has to be previously installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = pyo.SolverFactory('gurobi')\n",
    "\n",
    "solver_results = solver.solve(instance, keepfiles=False, tee=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Results**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract information on variables through the model output to .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path        = \"../data/input/openMASTER_Data.xlsx\"\n",
    "output_path = \"../data/tmp/output\"\n",
    "sheetname   = \"Output\"\n",
    "\n",
    "d_vars_from_instance = openMASTER.export_model_to_csv(path, output_path, sheetname, instance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading variable information from .csv to a dictionary containing all outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_vars = openMASTER.import_results_from_csv(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0517a97abf0a6b47b3d9f8b7b88c86ebe679f61210aefcb79cf5ebc38f36513"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
